# -*- coding: utf-8 -*-
"""AI-finalpoject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FxJ_jQEGHlUPdPlnMtLQCI6YC_9ZTlac

# **1. Libraries:**
"""

#import the reqired libraries
import numpy as np
import pandas as pd
import json
from sklearn.model_selection import train_test_split
from scipy.sparse.linalg import svds

"""# **2. Load Data Set**"""

from google.colab import drive
drive.mount('/content/drive')

# Import the dataset and give the column names
columns=['userId', 'productId', 'ratings','timestamp']
electronics_dataset=pd.read_csv('/content/drive/MyDrive/AI Final Project/Copy of ratings_Electronics.csv',names=columns)
electronics_dataset.drop('timestamp',axis=1,inplace=True)

electronics_dataset.head()
electronics_dataset.info()

#Check the number of rows and columns
print('shape of the dataset (row,col):',electronics_dataset.shape)

#Check the datatypes
electronics_dataset.dtypes

#Taking subset of the dataset
electronics_dataset_subset=electronics_dataset.iloc[:50000,0:]
electronics_dataset_subset.info()
print('\n')

#Summary
electronics_dataset_subset['ratings'].describe().transpose()

#minimum and maximum ratings
print('\n')
print('Minimum:',electronics_dataset_subset.ratings.min())
print('Maximum:',electronics_dataset_subset.ratings.max())

# Count of unique user and product in the subset data
print('unique users = ', electronics_dataset_subset['userId'].nunique())
print('unique product = ', electronics_dataset_subset['productId'].nunique())

"""# **3. Taking the top 15 users**"""

#Check the top 15 users based on ratings (Count)
unique_users=electronics_dataset_subset.groupby('userId')
most_rated=unique_users.size().sort_values(ascending=False)[:15]
print('Top 15 users based on ratings: \n',most_rated)

# working on best 15 users based on the count of their ranking:
# we call it final data
# electronics_dataset_final has the users who have rated 15 or more items.

counts=electronics_dataset_subset.userId.value_counts()
electronics_dataset_final=electronics_dataset_subset[electronics_dataset_subset.userId.isin(counts[counts>=15].index)]

print('Number of users who have rated 15 or more items =', len(electronics_dataset_final))
print('Number of unique users in the final data = ', electronics_dataset_final['userId'].nunique())
print('Number of unique products in the final data = ', electronics_dataset_final['productId'].nunique())

#constructing the pivot table for Algorithm
final_ratings_matrix = electronics_dataset_final.pivot(index = 'userId', columns ='productId', values = 'ratings').fillna(0)
final_ratings_matrix

print('Shape of final_ratings_matrix: ', final_ratings_matrix.shape)
#It shows that it is a sparse matrix. So, many cells are filled with 0 values.

"""# **4. Splitting the data**"""

# Split the data randomnly into train and test datasets into 70:30 ratio
# with train_test_split function
train_data, test_data = train_test_split(electronics_dataset_final, test_size = 0.3, random_state=0)

print('Shape of training data: ',train_data.shape)
print('Shape of testing data: ',test_data.shape)

"""# **5. Building Collaborative Filtering recommender model**"""

electronics_dataset_final_CF = pd.concat([train_data, test_data]).reset_index()
electronics_dataset_final_CF.head()

"""## User base collaborative Model"""

# Constructing the pivot table for Algorithm
real_pivot_table = electronics_dataset_final_CF.pivot(index = 'userId', columns ='productId', values = 'ratings').fillna(0)

#define user index
real_pivot_table['user_index'] = np.arange(0, real_pivot_table.shape[0], 1)
real_pivot_table.set_index(['user_index'], inplace=True)

"""## Singular Value Decomposition
It shows that it is a sparse matrix. So, many cells are filled with 0 values.
As this is a sparse matrix we will use SVD.
"""

# Singular Value Decomposition
P, sigma, Qt = svds(real_pivot_table, k = 10)
# Construct diagonal array in SVD
sigma = np.diag(sigma)

#Predicted ratings
all_user_predicted_ratings = np.dot(np.dot(P, sigma), Qt)
# Convert predicted ratings to dataframe
predicate_pivot_table = pd.DataFrame(all_user_predicted_ratings, columns = real_pivot_table.columns)

# Print Real Rating and Predicate Rating:
# so Actual ratings given by users:
print("Pivot Table:")
real_pivot_table

# and Predicate Rating given by SVD:
print("Predicate Table:")
predicate_pivot_table

# Recommend the items with the highest predicted ratings
def recommend_items(userID, real_pivot_table, predicate_pivot_table, num_recommendations):
    # index starts at 0
    user_index = userID-1

    # Get and sort the user's ratings
        #sorted_user_ratings:
    sorted_user_ratings = real_pivot_table.iloc[user_index].sort_values(ascending=False)
        #sorted_user_predictions:
    sorted_user_predictions = predicate_pivot_table.iloc[user_index].sort_values(ascending=False)

    temp = pd.concat([sorted_user_ratings, sorted_user_predictions], axis=1)
    temp.index.name = 'Recommended Items'
    temp.columns = ['user_ratings', 'user_predictions']
    temp = temp.loc[temp.user_ratings == 0]
    temp = temp.sort_values('user_predictions', ascending=False)
    print('\nBelow are the recommended items for user(user_id = {}):\n'.format(userID))
    print(temp.head(num_recommendations))

# pivod_df --> before SVD
# preds_df --> after SVD
userID = 4
num_recommendations = 5
recommend_items(userID, real_pivot_table, predicate_pivot_table, num_recommendations)



"""# **6. Evaluation**"""

# Actual ratings (users)
real_pivot_table.head()
# Average ACTUAL rating for each product
real_pivot_table.mean().head()

# Predicted ratings
predicate_pivot_table.head()
# Average PREDICTED rating for each product
predicate_pivot_table.mean().head()

rmse_df = pd.concat([final_ratings_matrix.mean(), predicate_pivot_table.mean()], axis=1)
rmse_df.columns = ['Avg_REAL_ratings', 'Avg_PREDICATE_ratings']
rmse_df['item_index'] = np.arange(0, rmse_df.shape[0], 1)
rmse_df.head()


RMSE = round((((rmse_df.Avg_REAL_ratings - rmse_df.Avg_PREDICATE_ratings) ** 2).mean() ** 0.5), 5)
print('\nRMSE = {} \n'.format(RMSE))